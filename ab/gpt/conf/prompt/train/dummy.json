{
    "dummy_key": {
        "prompt": [
            "Role & Context: You are an expert AI architect specialized in deep learning. Your task is to implement the missing components (`pass` blocks) of a strict PyTorch model skeleton achieves an accuracy of {accuracy}.",
            "Input Context: The following code skeleton provides fixed infrastructure (Wrappers, AMP, Training Loop). You must keep all existing code intact and ONLY implement the missing logic.",
            "[CODE SKELETON START]\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport gc\nimport torchvision\nfrom torch.nn import MaxPool2d\nfrom torch.amp import autocast, GradScaler\n\n# ==========================================\n# 1. FIXED INFRASTRUCTURE (DO NOT MODIFY)\n# ==========================================\n",
            "class TorchVision(nn.Module):\n    def __init__(self, model: str, weights: str = \"DEFAULT\", unwrap: bool = True, truncate: int = 1, in_channels: int = 3):\n        super().__init__()\n        self.adapter = nn.Conv2d(in_channels, 3, kernel_size=1) if in_channels != 3 else nn.Identity()\n        kwargs = {{\"aux_logits\": False}} if \"inception\" in model.lower() else {{}}\n        try:\n            if hasattr(torchvision.models, \"get_model\"):\n                self.m = torchvision.models.get_model(model, weights=weights, **kwargs)\n            else:\n                self.m = torchvision.models.__dict__[model](pretrained=bool(weights), **kwargs)\n        except:\n            if hasattr(torchvision.models, \"get_model\"):\n                self.m = torchvision.models.get_model(model, weights=weights)\n            else:\n                self.m = torchvision.models.__dict__[model](pretrained=bool(weights))\n        \n        if unwrap:\n            layers = []\n            for name, module in self.m.named_children():\n                if \"aux\" in name.lower(): continue\n                layers.append(module)\n            self.m = nn.Sequential(*(layers[:-truncate] if truncate else layers))\n        else:\n            self.m.head = nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if x.dim() == 2:\n            x = x.unsqueeze(-1).unsqueeze(-1)\n        return self.m(self.adapter(x))\n\ndef adaptive_pool_flatten(x):\n    if x.ndim == 4: return torch.nn.functional.adaptive_avg_pool2d(x, (1, 1)).flatten(1)\n    if x.ndim == 3: return x.mean(dim=1)\n    return x.flatten(1) if x.ndim > 2 else x\n\ndef autocast_ctx(enabled=True):\n    return autocast(\"cuda\", enabled=enabled)\ndef make_scaler(enabled=True):\n    return GradScaler(\"cuda\", enabled=enabled)\n\ndef supported_hyperparameters():\n    return {{ 'lr', 'dropout', 'momentum' }}\n\n# ==========================================\n# 2. DYNAMIC COMPONENTS (TO BE IMPLEMENTED)\n# ==========================================\n\ndef drop_conv3x3_block(in_channels, out_channels, stride=1, padding=1, bias=False, dropout_prob=0.0):\n    pass\n\nclass FractalBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, num_columns, loc_drop_prob, dropout_prob):\n        super().__init__()\n        self.num_columns = int(num_columns)\n        depth = 2 ** max(self.num_columns - 1, 0)\n        blocks = []\n        for i in range(depth):\n            level = nn.ModuleList()\n            for j in range(self.num_columns):\n                if (i + 1) % (2 ** j) == 0:\n                    in_ch_ij = in_channels if (i + 1 == 2 ** j) else out_channels\n                    level.append(drop_conv3x3_block(in_ch_ij, out_channels, dropout_prob=dropout_prob))\n            blocks.append(level)\n        self.blocks = nn.ModuleList(blocks)\n\n    def forward(self, x):\n        outs = [x] * self.num_columns\n        for level_block in self.blocks:\n            outs_i = [blk(inp) for blk, inp in zip(level_block, outs)]\n            joined = torch.stack(outs_i, dim=0).mean(dim=0)\n            outs[:len(level_block)] = [joined] * len(level_block)\n        return outs[0]\n\nclass FractalUnit(nn.Module):\n    def __init__(self, in_channels, out_channels, num_columns, loc_drop_prob, dropout_prob):\n        super().__init__()\n        self.block = FractalBlock(in_channels, out_channels, num_columns, loc_drop_prob, dropout_prob)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        return self.pool(self.block(x))\n\nclass Net(nn.Module):\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        self.use_amp = prm.get(\"use_amp\", False)\n        pass\n\n    def infer_dimensions_dynamically(self, in_shape, num_classes):\n        self.to(self.device)\n        self.eval()\n        with torch.no_grad():\n            C = in_shape[1] if len(in_shape)==4 else in_shape[0]\n            dummy = torch.zeros(1, C, 224, 224).to(self.device)\n            output_feat = self.forward(dummy, is_probing=True)\n            dim_fused = output_feat.shape[1]\n        self.classifier = nn.Linear(dim_fused, num_classes)\n        self.train()\n\n    @staticmethod\n    def _norm4d(x: torch.Tensor) -> torch.Tensor:\n        if x.dim() == 4: return x\n        if x.dim() == 5:\n            B, T, C, H, W = x.shape\n            return x.reshape(B * T, C, H, W)\n        raise ValueError(f\"Expected 4D/5D input, got {{tuple(x.shape)}}\")\n\n    def forward(self, x: torch.Tensor, is_probing: bool = False) -> torch.Tensor:\n        pass\n\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criterion = nn.CrossEntropyLoss().to(self.device)\n        self.optimizer = torch.optim.SGD(self.parameters(), lr=prm['lr'], momentum=prm['momentum'])\n        self._scaler = make_scaler(enabled=self.use_amp)\n\n    def learn(self, train_data):\n        self.train()\n        scaler = self._scaler\n        train_iter = iter(train_data)\n        try:\n            for batch_idx, (inputs, labels) in enumerate(train_iter):\n                inputs = inputs.to(self.device).float()\n                labels = labels.to(self.device)\n                self.optimizer.zero_grad(set_to_none=True)\n                with autocast_ctx(enabled=self.use_amp):\n                    outputs = self(inputs)\n                    loss = self.criterion(outputs, labels)\n                if not torch.isfinite(loss): continue\n                if self.use_amp:\n                    scaler.scale(loss).backward()\n                    scaler.unscale_(self.optimizer)\n                    nn.utils.clip_grad_norm_(self.parameters(), 3.0)\n                    scaler.step(self.optimizer)\n                    scaler.update()\n                else:\n                    loss.backward()\n                    nn.utils.clip_grad_norm_(self.parameters(), 3.0)\n                    self.optimizer.step()\n        finally:\n            if hasattr(train_iter, 'shutdown'): train_iter.shutdown()\n            del train_iter\n            gc.collect()\n[CODE SKELETON END]",
            "Implementation Requirements",
            "1. **Implement `drop_conv3x3_block`**: Return an `nn.Sequential` block containing a valid chain of Conv2d, BatchNorm, Activations (e.g., ReLU/SiLU), and Dropout.",
            "2. **Implement `Net.__init__`**: select `self.pattern from \"Parallel_Triple, Ensemble_Backbones_to_Fractal, Split_A_Parallel_BF\"`. available_backbones is [convnext_tiny, densenet121, densenet161, densenet169, densenet201, efficientnet_b0, efficientnet_b1, efficientnet_b2, efficientnet_b3, efficientnet_b4, efficientnet_v2_s, googlenet, inception_v3, mnasnet0_5, mnasnet0_75, mnasnet1_0, mnasnet1_3, mobilenet_v2, mobilenet_v3_large, mobilenet_v3_small, regnet_x_1_6gf, regnet_x_3_2gf, regnet_x_400mf, regnet_x_800mf, regnet_y_1_6gf, regnet_y_3_2gf, regnet_y_400mf, regnet_y_800mf, resnet18, resnet34, resnet50, resnext50_32x4d, shufflenet_v2_x0_5, shufflenet_v2_x1_0, shufflenet_v2_x1_5, shufflenet_v2_x2_0, squeezenet1_0, squeezenet1_1, swin_t, swin_v2_t]. Initialize `self.backbone_a` and `self.backbone_b` from `available_backbones` using the `TorchVision` wrapper, Use specific model names and correct `in_channels` as the parameter. Initialize `self.features` as an `nn.Sequential` of `FractalUnit` modules with growing channels, use only one or two layers of FractalUnit to avoid excessively small output. Call `self.infer_dimensions_dynamically(in_shape, out_shape[0])` and initialize `self._scaler`.",
            "3. **Implement `Net.forward` (CRITICAL)**: Implement the forward pass based on the selected `self.pattern`. **Dimension Safety**: If the topology feeds the output of a Backbone/Vector into `self.features` (Fractal), you MUST reshape the vector to 4D (`unsqueeze`) and upscale it using `torch.nn.functional.interpolate` to at least `(14, 14)` before passing it to the fractal network. Example safety check for Vector inputs: `if tensor.dim() == 2: tensor = tensor.unsqueeze(-1).unsqueeze(-1)`. `if tensor.shape[-1] < 14: tensor = F.interpolate(tensor, size=(14,14))`",
            "Output Instructions: You must output ONLY the implementation of the three missing components, wrapped in the following XML tags: 1. <block> ... code for drop_conv3x3_block ... </block> 2. <init> ... code for Net.__init__ ... </init> 3. <forward> ... code for Net.forward ... </forward>. Do not output the full file. Do not output any markdown formatting (like ```python)."
        ],
        "input_list": [
            {
                "para": "accuracy",
                "value": "accuracy"
            }
        ],
        "task": "img-classification"
    }
}